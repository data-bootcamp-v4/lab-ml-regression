{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=42a0be03-ff19-497a-9499-9837dc3245c5 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('42a0be03-ff19-497a-9499-9837dc3245c5').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Display basic info\n",
    "spaceship.head()\n",
    "\n",
    "# Handle missing data\n",
    "spaceship.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Preprocessing\n",
    "# Select numeric and categorical columns\n",
    "numeric_features = spaceship.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = spaceship.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Define preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Define target and features\n",
    "X = spaceship.drop(columns=['Transported'])  # Replace 'Transported' with the actual target column if different\n",
    "y = spaceship['Transported'].astype(int)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Bagging and Pasting\n",
    "bagging_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(base_estimator=RandomForestClassifier(), n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pasting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(base_estimator=RandomForestClassifier(), n_estimators=100, bootstrap=False, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Random Forest\n",
    "random_forest_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Gradient Boosting\n",
    "gradient_boosting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "# Adaptive Boosting\n",
    "adaptive_boosting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X luego de la transformación: (6954, 19238)\n",
      "\n",
      "=== Entrenando Bagging... ===\n",
      "Bagging entrenado. Realizando predicciones...\n",
      "Bagging Accuracy: 0.7740\n",
      "\n",
      "=== Entrenando Pasting... ===\n",
      "Pasting entrenado. Realizando predicciones...\n",
      "Pasting Accuracy: 0.7775\n",
      "\n",
      "=== Entrenando Random Forest... ===\n",
      "Random Forest entrenado. Realizando predicciones...\n",
      "Random Forest Accuracy: 0.7746\n",
      "\n",
      "=== Entrenando Gradient Boosting... ===\n",
      "Gradient Boosting entrenado. Realizando predicciones...\n",
      "Gradient Boosting Accuracy: 0.7775\n",
      "\n",
      "=== Entrenando Adaptive Boosting... ===\n",
      "Adaptive Boosting entrenado. Realizando predicciones...\n",
      "Adaptive Boosting Accuracy: 0.7706\n",
      "\n",
      "El mejor modelo es Pasting con una exactitud de 0.7775\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1. Importar librerías\n",
    "# =========================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Quita estas dos líneas si tu scikit-learn es < 1.2\n",
    "# from sklearn import set_config\n",
    "# set_config(transform_output=\"pandas\")\n",
    "\n",
    "# =========================================================\n",
    "# 2. Cargar el dataset\n",
    "# =========================================================\n",
    "url = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\"\n",
    "spaceship = pd.read_csv(url)\n",
    "\n",
    "# =========================================================\n",
    "# 3. Manejo de datos faltantes\n",
    "# =========================================================\n",
    "# Rellenar valores faltantes con 'forward fill'\n",
    "spaceship.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# =========================================================\n",
    "# 4. Definir características numéricas y categóricas\n",
    "# =========================================================\n",
    "numeric_features = spaceship.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = spaceship.select_dtypes(include=['object']).columns\n",
    "\n",
    "# =========================================================\n",
    "# 5. ColumnTransformer para preprocesamiento\n",
    "# =========================================================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 6. Definir X e y\n",
    "# =========================================================\n",
    "X = spaceship.drop(columns=['Transported'])  \n",
    "y = spaceship['Transported'].astype(int)\n",
    "\n",
    "# =========================================================\n",
    "# 7. Dividir en train y test\n",
    "# =========================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# =========================================================\n",
    "# 8. (Opcional) Probar con subset para debugging rápido\n",
    "# =========================================================\n",
    "# X_train = X_train.head(2000)\n",
    "# y_train = y_train.head(2000)\n",
    "\n",
    "# =========================================================\n",
    "# 9. (Opcional) Revisar cuántas columnas produce la transformación\n",
    "# =========================================================\n",
    "X_preprocessed_sample = preprocessor.fit_transform(X_train)\n",
    "print(\"Shape de X luego de la transformación:\", X_preprocessed_sample.shape)\n",
    "\n",
    "# =========================================================\n",
    "# 10. Definir modelos con parámetros optimizados\n",
    "# =========================================================\n",
    "\n",
    "bagging_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(\n",
    "            n_estimators=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pasting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', BaggingClassifier(\n",
    "        base_estimator=RandomForestClassifier(\n",
    "            n_estimators=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        n_estimators=10,\n",
    "        bootstrap=False,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "random_forest_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "gradient_boosting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "adaptive_boosting_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(\n",
    "        n_estimators=50,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# 11. Entrenar y evaluar los modelos\n",
    "# =========================================================\n",
    "models = {\n",
    "    'Bagging': bagging_model,\n",
    "    'Pasting': pasting_model,\n",
    "    'Random Forest': random_forest_model,\n",
    "    'Gradient Boosting': gradient_boosting_model,\n",
    "    'Adaptive Boosting': adaptive_boosting_model\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Entrenando {model_name}... ===\")\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{model_name} entrenado. Realizando predicciones...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[model_name] = accuracy\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# 12. Seleccionar mejor modelo\n",
    "# =========================================================\n",
    "best_model = max(results, key=results.get)\n",
    "print(f\"\\nEl mejor modelo es {best_model} con una exactitud de {results[best_model]:.4f}\")\n",
    "#hecho\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
