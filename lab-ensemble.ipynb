{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with the same Spaceship Titanic data, like the previous Lab. The data can be found here:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "https://github.com/data-bootcamp-v4/data/blob/main/spaceship_titanic.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Lab, you should try different ensemble methods in order to see if can obtain a better model than before. In order to do a fair comparison, you should perform the same feature scaling, engineering applied in previous Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error, precision_score, accuracy_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "   Transported  \n",
       "0        False  \n",
       "1         True  \n",
       "2        False  \n",
       "3        False  \n",
       "4         True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same as before:\n",
    "- Feature Scaling\n",
    "- Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "spaceship.dropna(inplace=True)\n",
    "spaceship[\"Cabin\"] = spaceship[\"Cabin\"].apply(lambda x: x.split(\"/\")[0])\n",
    "spaceship.drop(columns = [\"PassengerId\",\"Name\"], inplace=True)\n",
    "\n",
    "spaceship2 = spaceship.__deepcopy__()\n",
    "spacedummies = pd.get_dummies(spaceship2, columns=['HomePlanet', 'Cabin', 'Destination'], drop_first=False)\n",
    "spacedummies = pd.get_dummies(spacedummies, columns=['CryoSleep', 'VIP', 'Transported'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "target = spacedummies[\"Transported_True\"]\n",
    "features = spacedummies.drop(\"Transported_True\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With normalization\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "binary_features = ['HomePlanet_Earth', 'HomePlanet_Europa', 'HomePlanet_Mars', \n",
    "                  'Cabin_A', 'Cabin_B', 'Cabin_C', 'Cabin_D', 'Cabin_E', \n",
    "                  'Cabin_F', 'Cabin_G', 'Cabin_T', \n",
    "                  'Destination_55 Cancri e', 'Destination_PSO J318.5-22', \n",
    "                  'Destination_TRAPPIST-1e', 'CryoSleep_True', 'VIP_True']\n",
    "\n",
    "numerical_features = X_train.columns.difference(binary_features) # Identify numerical features\n",
    "\n",
    "# Normalize only the numerical features\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(X_train[numerical_features])\n",
    "\n",
    "# Transform the numerical features\n",
    "X_train_norm = normalizer.transform(X_train[numerical_features])\n",
    "X_test_norm = normalizer.transform(X_test[numerical_features])\n",
    "\n",
    "# Convert to DataFrame, keeping the original indices\n",
    "X_train_norm = pd.DataFrame(X_train_norm, columns=numerical_features, index=X_train.index)\n",
    "X_test_norm = pd.DataFrame(X_test_norm, columns=numerical_features, index=X_test.index)\n",
    "\n",
    "# Combine normalized numerical features with unchanged binary features\n",
    "X_train_norm = pd.concat([X_train_norm, X_train[binary_features]], axis=1)\n",
    "X_test_norm = pd.concat([X_test_norm, X_test[binary_features]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection** - now you will try to apply different ensemble methods in order to get a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous performance: <br>\n",
    "\n",
    "- Accuracy: 0.7844175491679274 <br>\n",
    "- Precision: 0.7993630573248408 <br>\n",
    "- Recall: 0.7594553706505295 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy bag: 0.7829046898638427\n",
      "Precision bag: 0.7766272189349113\n",
      "Recall bag: 0.794251134644478\n",
      "\n",
      "\n",
      "Accuracy paste: 0.7768532526475038\n",
      "Precision paste: 0.7798165137614679\n",
      "Recall paste: 0.7715582450832073\n"
     ]
    }
   ],
   "source": [
    "#your code here -> bagging\n",
    "bagging_reg = BaggingClassifier(DecisionTreeClassifier(\n",
    "                                max_depth=20\n",
    "                                ),                               \n",
    "                               n_estimators=200,\n",
    "                               max_samples = 1000,\n",
    "                               #bootstrap = False,\n",
    "                               n_jobs=-1\n",
    "                               )\n",
    "\n",
    "bagging_reg.fit(X_train_norm, y_train)\n",
    "\n",
    "pred = bagging_reg.predict(X_test_norm)\n",
    "\n",
    "precision = precision_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "\n",
    "print(\"Accuracy bag:\", accuracy)\n",
    "print(\"Precision bag:\", precision)\n",
    "print(\"Recall bag:\", recall)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#your code here -> paste\n",
    "bagging_reg = BaggingClassifier(DecisionTreeClassifier(\n",
    "                                ##max_depth=20\n",
    "                                ),                               \n",
    "                               n_estimators=200,\n",
    "                               max_samples = 1000,\n",
    "                               bootstrap = False,\n",
    "                               n_jobs=-1\n",
    "                               )\n",
    "\n",
    "bagging_reg.fit(X_train_norm, y_train)\n",
    "\n",
    "pred = bagging_reg.predict(X_test_norm)\n",
    "\n",
    "precision = precision_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "\n",
    "print(\"Accuracy paste:\", accuracy)\n",
    "print(\"Precision paste:\", precision)\n",
    "print(\"Recall paste:\", recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7881996974281392\n",
      "Precision: 0.7917304747320061\n",
      "Recall: 0.7821482602118003\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=200,\n",
    "                             max_depth=20)\n",
    "\n",
    "forest.fit(X_train_norm, y_train)\n",
    "\n",
    "pred = forest.predict(X_test_norm)\n",
    "\n",
    "precision = precision_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.791981845688351\n",
      "Precision: 0.7880597014925373\n",
      "Recall: 0.7987897125567323\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "gb_reg = GradientBoostingClassifier(max_depth=20,\n",
    "                                   n_estimators=200)\n",
    "\n",
    "gb_reg.fit(X_train_norm, y_train)\n",
    "\n",
    "pred = gb_reg.predict(X_test_norm)\n",
    "\n",
    "precision = precision_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utilizador\\anaconda3\\envs\\conda3-12\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7715582450832073\n",
      "Precision: 0.7597684515195369\n",
      "Recall: 0.794251134644478\n"
     ]
    }
   ],
   "source": [
    "ada_reg = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20),\n",
    "                            n_estimators=200\n",
    "                            )\n",
    "\n",
    "ada_reg.fit(X_train_norm, y_train)\n",
    "\n",
    "pred = ada_reg.predict(X_test_norm)\n",
    "\n",
    "precision = precision_score(y_test, pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "recall = recall_score(y_test, pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is the best and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMost metrics give us an accuracy between 0.77-0.79. \\nWhile KNN's scored higher in Precision, GradientBoost and Bagging performed better in Recall.\\n\\nFor our metric of identifying if passenger was transported or not, Recall might be our most valued metric, so GradientBoost.\\nHowever, we should procede with some crossvalidation on all tests because there's high variation depending on sampling, and our metrics are too close for a definitive answer.\\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comment here\n",
    "\"\"\"\n",
    "Most metrics give us an accuracy between 0.77-0.79. \n",
    "While KNN's scored higher in Precision, GradientBoost and Bagging performed better in Recall.\n",
    "\n",
    "For our metric of identifying if passenger was transported or not, Recall might be our most valued metric, so GradientBoost.\n",
    "However, we should procede with some crossvalidation on all tests because there's high variation depending on sampling, and our metrics are too close for a definitive answer.\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
