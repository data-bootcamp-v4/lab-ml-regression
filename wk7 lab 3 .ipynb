{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "501f8caf-5103-4c60-aef2-7ebeef5f2ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0.3459310529553151\n",
      "RMSE 0.39368720046890815\n",
      "R2 score 0.37995072819739184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "spaceship = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/spaceship_titanic.csv\")\n",
    "spaceship.head()\n",
    "\n",
    "spaceship.shape\n",
    "spaceship.dtypes\n",
    "spaceship.isnull().sum()\n",
    "spaceship.dropna(inplace=True)\n",
    "\n",
    "spaceship['Cabin']=spaceship['Cabin'].str[0]\n",
    "spaceship=spaceship.drop(['PassengerId','Name'],axis =1)\n",
    "\n",
    "\n",
    "spaceship_with_dummies = pd.get_dummies(spaceship,drop_first=True)\n",
    "X = spaceship_with_dummies.drop('Transported',axis=1)\n",
    "y = spaceship_with_dummies['Transported']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.2,random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "normalizer.fit(X_train)\n",
    "\n",
    "X_train_norm = normalizer.transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "X_train_norm = pd.DataFrame(X_train_norm,columns = X_train.columns)\n",
    "X_test_norm = pd.DataFrame(X_test_norm,columns = X_test.columns)\n",
    "\n",
    "# Bagging and Pasting\n",
    "bagging_reg = BaggingRegressor(DecisionTreeRegressor(max_depth=20),\n",
    "                               n_estimators=200,\n",
    "                               max_samples = 1000)\n",
    "bagging_reg.fit(X_train_norm, y_train)\n",
    "pred = bagging_reg.predict(X_test_norm)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", bagging_reg.score(X_test_norm, y_test))\n",
    "\n",
    "\n",
    "# Random Forests\n",
    "forest = RandomForestRegressor(n_estimators=100,\n",
    "                             max_depth=10)\n",
    "forest.fit(X_train_norm, y_train)\n",
    "pred = forest.predict(X_test_norm)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", forest.score(X_test_norm, y_test))\n",
    "\n",
    "\n",
    "# Gradient Boosting\n",
    "gb_reg = GradientBoostingRegressor(max_depth=4,\n",
    "                                   n_estimators=100)\n",
    "\n",
    "gb_reg.fit(X_train_norm, y_train)\n",
    "pred = gb_reg.predict(X_test_norm)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", gb_reg.score(X_test_norm, y_test))\n",
    "\n",
    "# Adaptive Boosting\n",
    "ada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),\n",
    "                            n_estimators=20)\n",
    "\n",
    "ada_reg.fit(X_train_norm, y_train)\n",
    "pred = ada_reg.predict(X_test_norm)\n",
    "\n",
    "print(\"MAE\", mean_absolute_error(pred, y_test))\n",
    "print(\"RMSE\", mean_squared_error(pred, y_test, squared=False))\n",
    "print(\"R2 score\", ada_reg.score(X_test_norm, y_test))\n",
    "\n",
    "# after many times minor adjusting on parameters for all above 4 models, we found Gradient Boosting is best with highest R2 score at 0.468\n",
    "# the reson maybe that this model best match this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbb0f71-4b45-44f7-ba03-eaed4ab6bd84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
